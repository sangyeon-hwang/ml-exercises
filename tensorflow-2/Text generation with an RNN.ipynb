{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text generation with an RNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"zWL4fEK6y5JU","colab_type":"code","colab":{}},"source":["!pip install tensorflow==2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c02HEwRXu_nq","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i0_p9xSYzJAv","colab_type":"code","outputId":"51e9004a-73e1-43ad-92fc-1490c3e558de","executionInfo":{"status":"ok","timestamp":1576719510813,"user_tz":-540,"elapsed":42267,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tf.__version__"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.0.0'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"uwkqEhuazJtf","colab_type":"code","outputId":"aa68f0b8-7a77-47c6-9e6d-62a729edf30e","executionInfo":{"status":"ok","timestamp":1576719510814,"user_tz":-540,"elapsed":42255,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["path_to_file = tf.keras.utils.get_file('shakespeare.txt',\n","                                       'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n","1122304/1115394 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q0YhWgPX8CFV","colab_type":"text"},"source":["### Read the data"]},{"cell_type":"code","metadata":{"id":"t5SscRMo7fmY","colab_type":"code","outputId":"ae1b8a5a-aa58-4157-d220-42487b3a0b1d","executionInfo":{"status":"ok","timestamp":1576719510815,"user_tz":-540,"elapsed":42245,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["with open(path_to_file, 'rb') as f:\n","    text = f.read().decode(encoding='utf-8')\n","\n","print(f\"Length of text: {len(text)} characters\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Length of text: 1115394 characters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eQMqozdJ8NJ-","colab_type":"code","outputId":"112dabb1-3fed-4942-da30-44da6b06e7d4","executionInfo":{"status":"ok","timestamp":1576719510815,"user_tz":-540,"elapsed":42230,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["# Example\n","print(text[:250])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7tnJuZy88OjH","colab_type":"text"},"source":["The unique characters in the file"]},{"cell_type":"code","metadata":{"id":"qpOknJP59OGa","colab_type":"code","outputId":"acd1be0d-b17f-47aa-c9c2-5bd998a10335","executionInfo":{"status":"ok","timestamp":1576719510816,"user_tz":-540,"elapsed":42223,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["vocab = sorted(set(text))\n","print(f\"{len(vocab)} unique characters\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["65 unique characters\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4XvV_bip9hMe","colab_type":"text"},"source":["Character <-> integer mappers"]},{"cell_type":"code","metadata":{"id":"zupcGKO9C1cw","colab_type":"code","colab":{}},"source":["char2idx = {u:i for i, u in enumerate(vocab)}\n","idx2char = np.array(vocab)\n","\n","text_as_int = np.array([char2idx[c] for c in text])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o3FNG2JhDHyh","colab_type":"code","outputId":"1d046802-6fac-4d0d-f377-bc2c9bafd5e5","executionInfo":{"status":"ok","timestamp":1576719511281,"user_tz":-540,"elapsed":42674,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Example\n","print(\"{} are mapped to {}\".format(repr(text[:13]),\n","                                   text_as_int[:13]))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["'First Citizen' are mapped to [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B4NC029lDZOx","colab_type":"text"},"source":["### Create training examples and targets\n","\n","For each *input* sequence, its *target* sequence will have the same length, except shifted one character to the right."]},{"cell_type":"code","metadata":{"id":"6y4QBimv3ZbT","colab_type":"code","outputId":"cd4813ed-3859-445e-e0f7-d8a415ade090","executionInfo":{"status":"ok","timestamp":1576719511282,"user_tz":-540,"elapsed":42666,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["seq_length = 100\n","examples_per_epoch = len(text) // (seq_length + 1)\n","print(\"examples_per_epoch =\", examples_per_epoch)\n","\n","# Create training examples and targets.\n","char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n","\n","# Example\n","for i in char_dataset.take(5):\n","    print(idx2char[i.numpy()])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["examples_per_epoch = 11043\n","F\n","i\n","r\n","s\n","t\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1BPn-Ujx5I8c","colab_type":"text"},"source":["Use the `batch` method to convert these individual characters to sequences of the desired size."]},{"cell_type":"code","metadata":{"id":"9Ea1XJ635e_z","colab_type":"code","outputId":"3f1a3929-51cb-44c3-8921-d7513dd99e38","executionInfo":{"status":"ok","timestamp":1576719511282,"user_tz":-540,"elapsed":42656,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["sequences = char_dataset.batch(seq_length, drop_remainder=True)\n","\n","for item in sequences.take(5):\n","    print(repr(''.join(idx2char[item.numpy()])))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n","' are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you'\n","\" know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us\"\n","\" kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it \"\n","'be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R940X5F9_wag","colab_type":"text"},"source":["For each sequence, duplicate and shift it to prepare the input and target.\n","\n","Use `map` to apply to each batch"]},{"cell_type":"code","metadata":{"id":"aWnP-Iyb5x-O","colab_type":"code","colab":{}},"source":["def split_input_target(sequence):\n","    input_text = sequence[:-1]\n","    target_text = sequence[1:]\n","    return input_text, target_text\n","\n","dataset = sequences.map(split_input_target)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uiAMqhIn_hEJ","colab_type":"code","outputId":"40d6668f-58ec-432d-d54c-f80b7d6b8a1c","executionInfo":{"status":"ok","timestamp":1576719511283,"user_tz":-540,"elapsed":42647,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["# Example\n","for input_example, target_example in dataset.take(1):\n","    print(\"Input sequence:\", repr(''.join(idx2char[input_example.numpy()])))\n","    print(\"Target sequence:\", repr(''.join(idx2char[target_example.numpy()])))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Input sequence: 'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYo'\n","Target sequence: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q9H_kg9qAM9y","colab_type":"text"},"source":["Expected training dynamics for a few time steps:"]},{"cell_type":"code","metadata":{"id":"8khm1dNMA_Fb","colab_type":"code","outputId":"c2833af8-2c5f-4fae-eecb-e18c2cdf4d5b","executionInfo":{"status":"ok","timestamp":1576719511284,"user_tz":-540,"elapsed":42641,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n","    print(\"Step\", i)\n","    print(\"  input: {} ({})\".format(input_idx, repr(idx2char[input_idx])))\n","    print(\"  expected output: {} ({})\".format(target_idx, repr(idx2char[target_idx])))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Step 0\n","  input: 18 ('F')\n","  expected output: 47 ('i')\n","Step 1\n","  input: 47 ('i')\n","  expected output: 56 ('r')\n","Step 2\n","  input: 56 ('r')\n","  expected output: 57 ('s')\n","Step 3\n","  input: 57 ('s')\n","  expected output: 58 ('t')\n","Step 4\n","  input: 58 ('t')\n","  expected output: 1 (' ')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"H2Rxk_sgBBSa","colab_type":"text"},"source":["### Create training batches"]},{"cell_type":"code","metadata":{"id":"orq_T3GKB9Ij","colab_type":"code","outputId":"3b9ea7a2-c550-4e7d-b9f3-6cb7d730e02d","executionInfo":{"status":"ok","timestamp":1576719511284,"user_tz":-540,"elapsed":42633,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["BATCH_SIZE = 64\n","BUFFER_SIZE = 10000\n","\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","dataset"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<BatchDataset shapes: ((64, 99), (64, 99)), types: (tf.int64, tf.int64)>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"PRTMZfRxDeJz","colab_type":"text"},"source":["### Model\n","\n","We will use\n","* `tf.keras.layers.Embedding`\n","* `tf.keras.layers.GRU`\n","* `tf.keras.layers.Dense`"]},{"cell_type":"code","metadata":{"id":"qFhzhuEaEYO4","colab_type":"code","outputId":"b496f6e2-67e1-4b9e-dedb-250a379e278b","executionInfo":{"status":"ok","timestamp":1576719511286,"user_tz":-540,"elapsed":39308,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["vocab_size = len(vocab)\n","print(\"vocab_size:\", vocab_size)\n","embedding_dim = 256\n","rnn_units = 1024"],"execution_count":16,"outputs":[{"output_type":"stream","text":["vocab_size: 65\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3-W1S72SFPKL","colab_type":"code","colab":{}},"source":["def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","    model = tf.keras.Sequential([\n","        tf.keras.layers.Embedding(vocab_size,\n","                                  embedding_dim,\n","                                  batch_input_shape=[batch_size, None]),\n","        tf.keras.layers.GRU(rnn_units,\n","                            return_sequences=True,\n","                            stateful=True,\n","                            recurrent_initializer='glorot_uniform'),\n","        tf.keras.layers.Dense(vocab_size)\n","    ])\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BjoXscOZRYhh","colab_type":"code","outputId":"89e41205-02a7-46a0-db87-8f472fcaa4c6","executionInfo":{"status":"ok","timestamp":1576677046693,"user_tz":-540,"elapsed":1125,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"source":["model = build_model(vocab_size, embedding_dim, rnn_units, BATCH_SIZE)\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (64, None, 256)           16640     \n","_________________________________________________________________\n","gru_1 (GRU)                  (64, None, 1024)          3938304   \n","_________________________________________________________________\n","dense_1 (Dense)              (64, None, 65)            66625     \n","=================================================================\n","Total params: 4,021,569\n","Trainable params: 4,021,569\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hgh8peaBRzQH","colab_type":"text"},"source":["The model predicts a sequence of characters as follows:\n","\n","![](https://www.tensorflow.org/tutorials/text/images/text_generation_training.png)"]},{"cell_type":"markdown","metadata":{"id":"7F_tw9TSR5vT","colab_type":"text"},"source":["### Try the model"]},{"cell_type":"code","metadata":{"id":"W2LjazbETBbg","colab_type":"code","outputId":"f57b8fb3-09df-41fb-85e5-91cfe845ee9d","executionInfo":{"status":"ok","timestamp":1576677523643,"user_tz":-540,"elapsed":4258,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["for input_example_batch, target_example_batch in dataset.take(1):\n","    example_batch_predictions = model(input_example_batch)\n","    print(example_batch_predictions.shape,\n","          \"# (batch_size, seq_length, vocab_size)\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(64, 99, 65) # (batch_size, seq_length, vocab_size)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qVhZif-BTUNS","colab_type":"text"},"source":["Note that the model can process sequences of any length.\n","\n","Now let's try to *actualize* the prediction by sampling each character from the output distribution."]},{"cell_type":"code","metadata":{"id":"iS8ahWUBTnQe","colab_type":"code","colab":{}},"source":["sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n","sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U8T8isRgUIEz","colab_type":"code","outputId":"c254a90a-104f-43d9-a91e-13c84e61b3af","executionInfo":{"status":"ok","timestamp":1576677901779,"user_tz":-540,"elapsed":944,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["print(\"Input:\\n\", repr(''.join(idx2char[input_example_batch[0]])))\n","print()\n","print(\"Prediction:\\n\", repr(''.join(idx2char[sampled_indices])))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Input:\n"," \" thee burnt.\\n\\nPAULINA:\\nI care not:\\nIt is an heretic that makes the fire,\\nNot she which burns in't. \"\n","\n","Prediction:\n"," \"laYWLmPE!mrUVmOvXEMMRtCSyTbhmrGbZuvuPFyWpCWcEk'sN.UHP!YrsgICvYYqc'juhJ&FOP ;oENRB-e:hIA\\nq!BK'vlSVnn\"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QcukeJ-GU4EI","colab_type":"text"},"source":["### Train the model"]},{"cell_type":"code","metadata":{"id":"DgfvGvQiVFkz","colab_type":"code","colab":{}},"source":["def loss(labels, logits):\n","    \"\"\"\n","    labels: (batch, seq)\n","        Each value is an index corresponding to the true label.\n","    logits: (batch, seq, vocab)\n","        Each [i,j,:] is a vector of logits over the characters.\n","    \"\"\"\n","    return tf.keras.losses.sparse_categorical_crossentropy(\n","        labels, logits, from_logits=True\n","    )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IqijETl2XIl4","colab_type":"code","outputId":"dacd34f4-e983-404e-cf98-c28c042ea73b","executionInfo":{"status":"ok","timestamp":1576678626396,"user_tz":-540,"elapsed":952,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["example_batch_loss = loss(target_example_batch,\n","                          example_batch_predictions)\n","\n","print(\"Prediction shape:\", example_batch_predictions.shape,\n","      \"# (batch_size, seq_length, vocab_size)\")\n","print(\"Loss shape:\", example_batch_loss.shape)\n","print(\"Scalarized loss:\", example_batch_loss.numpy().mean())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Prediction shape: (64, 99, 65) # (batch_size, seq_length, vocab_size)\n","Loss shape: (64, 99)\n","Scalarized loss: 4.175805\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"90FLiWigXkHR","colab_type":"text"},"source":["Configure the training procedure:"]},{"cell_type":"code","metadata":{"id":"uyEdxIdnX1gW","colab_type":"code","colab":{}},"source":["model.compile(optimizer='adam',\n","              loss=loss)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yq10RhR4X5Ne","colab_type":"text"},"source":["Configure checkpoints"]},{"cell_type":"code","metadata":{"id":"sj6J0xMSYJzQ","colab_type":"code","colab":{}},"source":["# Directory to save the checkpoints\n","checkpoint_dir = './training_checkpoints'\n","# Name of the checkpoint files\n","checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\n","\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ROPPY1tYhqS","colab_type":"text"},"source":["Execute the training"]},{"cell_type":"code","metadata":{"id":"vxoh6i_SYqrG","colab_type":"code","outputId":"f2c6aaff-f227-4cf5-933a-15c4eef57dfe","executionInfo":{"status":"error","timestamp":1576684385695,"user_tz":-540,"elapsed":5458545,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":630}},"source":["EPOCHS = 10\n","history = model.fit(dataset,\n","                    epochs=EPOCHS,\n","                    callbacks=[checkpoint_callback])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","174/174 [==============================] - 915s 5s/step - loss: 2.6560\n","Epoch 2/10\n","174/174 [==============================] - 906s 5s/step - loss: 1.9653\n","Epoch 3/10\n","174/174 [==============================] - 901s 5s/step - loss: 1.7006\n","Epoch 4/10\n","174/174 [==============================] - 899s 5s/step - loss: 1.5524\n","Epoch 5/10\n","174/174 [==============================] - 915s 5s/step - loss: 1.4624\n","Epoch 6/10\n","174/174 [==============================] - 908s 5s/step - loss: 1.4011\n","Epoch 7/10\n","  2/174 [..............................] - ETA: 17:28 - loss: 1.3497"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-ab58f211fbc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model.fit(dataset,\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     callbacks=[checkpoint_callback])\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"hOsoXC5fttR8","colab_type":"code","outputId":"8cb38853-1725-46f8-fece-cb89b6b0a43b","executionInfo":{"status":"ok","timestamp":1576684430047,"user_tz":-540,"elapsed":3498,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":161}},"source":["!ls {checkpoint_dir}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["checkpoint\t\t    ckpt_4.index\n","ckpt_1.data-00000-of-00001  ckpt_5.data-00000-of-00001\n","ckpt_1.index\t\t    ckpt_5.index\n","ckpt_2.data-00000-of-00001  ckpt_6.data-00000-of-00001\n","ckpt_2.index\t\t    ckpt_6.index\n","ckpt_3.data-00000-of-00001  ckpt_7.data-00000-of-00001\n","ckpt_3.index\t\t    ckpt_7.index\n","ckpt_4.data-00000-of-00001\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t-KWhlP3Yypo","colab_type":"text"},"source":["## Generate text\n","### Restore the latest checkpoint\n","\n","For simplicity, we will use a batch size of 1 for predictions.\n","\n","Because of the way the RNN state is passed from timestep to timestep, to change the batch size, we need to rebuild the the model and restore the save weights."]},{"cell_type":"code","metadata":{"id":"sOm9TwUTdNVV","colab_type":"code","outputId":"f8f8337c-d098-4d30-aaf2-1b29e45363ec","executionInfo":{"status":"ok","timestamp":1576684449851,"user_tz":-540,"elapsed":1170,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.train.latest_checkpoint(checkpoint_dir)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'./training_checkpoints/ckpt_7'"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"V_LpJL0ruERD","colab_type":"code","colab":{}},"source":["model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n","\n","model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","\n","model.build(tf.TensorShape([1, None]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iUv3KavCuSOE","colab_type":"code","outputId":"7cc5e619-d189-470a-93f1-117a816ce6fe","executionInfo":{"status":"ok","timestamp":1576684568277,"user_tz":-540,"elapsed":997,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (1, None, 256)            16640     \n","_________________________________________________________________\n","gru_2 (GRU)                  (1, None, 1024)           3938304   \n","_________________________________________________________________\n","dense_2 (Dense)              (1, None, 65)             66625     \n","=================================================================\n","Total params: 4,021,569\n","Trainable params: 4,021,569\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L08UJbPiuTpe","colab_type":"text"},"source":["### Prediction loop\n","\n","![](https://www.tensorflow.org/tutorials/text/images/text_generation_sampling.png)"]},{"cell_type":"code","metadata":{"id":"mjcKp_houtGs","colab_type":"code","colab":{}},"source":["def generate_text(model, start_string):\n","    # Number of characters to generate\n","    num_generate = 1000\n","\n","    # Convert the start string to numbers.\n","    input_eval = [char2idx[ch] for ch in start_string]\n","    input_eval = tf.expand_dims(input_eval, 0)\n","    # -> (1, start_string)\n","\n","    text_generated = []\n","\n","    # Low temperatures result in more predictable texts.\n","    # High temperatures result in more surprising texts.\n","    # Experiment to find the best setting!\n","    temperature = 1.0\n","\n","    # Recall that the batch size is 1.\n","    model.reset_states()\n","    for i in range(num_generate):\n","        predictions = model(input_eval)\n","        # -> (1, seq, vocab)\n","        # Remove the batch dimension.\n","        predictions = tf.squeeze(predictions, 0)\n","        # -> (seq, vocab)\n","\n","        # Sample the word.\n","        predictions = predictions / temperature\n","        sample = tf.random.categorical(predictions, num_samples=1)\n","        # -> (seq, num_samples)\n","        predicted_idx = sample[-1,0].numpy()\n","        # -> scalar\n","\n","        # Pass the predicted word as the next input\n","        # along with the previous hidden state.\n","        input_eval = tf.expand_dims([predicted_idx], 0)\n","        # -> (1, 1)\n","\n","        text_generated.append(idx2char[predicted_idx])\n","\n","    return start_string + ''.join(text_generated)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f_INpSRMxMo_","colab_type":"code","outputId":"a0fce82e-972e-4f0b-d3d0-a5866e83c1c6","executionInfo":{"status":"ok","timestamp":1576686258229,"user_tz":-540,"elapsed":9171,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}},"colab":{"base_uri":"https://localhost:8080/","height":683}},"source":["print(\n","    generate_text(model, start_string=u\"ROMEO: \")\n",")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ROMEO: and woman make it,\n","Dear'st thy deed, and So let thee to the Tower.\n","\n","CLARINCE:\n","I word your husband's deviceth made I come?\n","What if the sup in me: I to my Lord God madam,\n","He is not the almits of my unburning wofur of their second men.\n","Is thither we name of vingia you, that ye'll stay this face.\n","\n","TRANIO:\n","O great plagion'd fellows are mo what ever I begon and even?\n","I was are touch'd the greatel treed to say your next:\n","What much thy deadure servant on mine,\n","Endorly thy royal travely's great doth\n","to your follow stay to-my; for Grouble ploce,\n","Which shall saig,\n","Hethinks shall hann that call'd to him?\n","\n","GLOUCESTER:\n","\n","CORIOLANUS:\n","I proy,' -quie the other relighty\n","Than seems are ill one of Goet to thy obitees to tale\n","give a well and falome!\n","\n","QUEEN:\n","I te Eny.\n","\n","LEONTES:\n","The kenant occarate to let.\n","\n","MENENIUS:\n","Ay, with that, you beholding thouse. Hather, had he take\n","To scark forward, fell on, nor in me;\n","And never bees as one with us, which\n","Tear my endity lord! Therefore do that is hope to take Thines.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2rTROEkTxS4h","colab_type":"text"},"source":["### Customized training"]},{"cell_type":"code","metadata":{"id":"LOH5PA7x0R2V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"outputId":"c4acc4a5-2adc-49c1-f5f7-fd94270efb24","executionInfo":{"status":"ok","timestamp":1576719856304,"user_tz":-540,"elapsed":987,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}}},"source":["model = build_model(vocab_size, embedding_dim, rnn_units, BATCH_SIZE)\n","model.summary()\n","optimizer = tf.keras.optimizers.Adam()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (64, None, 256)           16640     \n","_________________________________________________________________\n","gru_1 (GRU)                  (64, None, 1024)          3938304   \n","_________________________________________________________________\n","dense_1 (Dense)              (64, None, 65)            66625     \n","=================================================================\n","Total params: 4,021,569\n","Trainable params: 4,021,569\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aZZ4dkIS0mmI","colab_type":"code","colab":{}},"source":["@tf.function\n","def train_step(model, optimizer, inp, target):\n","    with tf.GradientTape() as tape:\n","        predictions = model(inp)\n","        loss = tf.reduce_mean(\n","            tf.keras.losses.sparse_categorical_crossentropy(target,\n","                                                            predictions,\n","                                                            from_logits=True))\n","    grads = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","    return loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ib580jV22Jki","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":442},"outputId":"8cbc31fe-33d6-45b5-c53a-c90a91e9ab5f","executionInfo":{"status":"ok","timestamp":1576724825490,"user_tz":-540,"elapsed":4362863,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}}},"source":["EPOCHS = 5\n","\n","for epoch in range(EPOCHS):\n","    start_time = time.time()\n","\n","    # Initialize the hidden state at the start of every epoch.\n","    # Initially, the hidden state is None.\n","    hidden = model.reset_states()\n","\n","    template = \"Epoch {} Batch {} Loss {}\"\n","    for batch_n, (inp, target) in enumerate(dataset):\n","        loss = train_step(model, optimizer, inp, target)\n","\n","        if not batch_n % 100:\n","            print(template.format(epoch+1, batch_n, loss))\n","    \n","    # Save the model every 5 epochs.\n","    if not (epoch+1) % 5:\n","        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n","    \n","    print(\"Epoch {} Loss {:.4f}\".format(epoch+1, loss))\n","    print(\"Time taken for the epoch: {} sec\".format(time.time() - start_time))\n","    print()\n","\n","model.save_weights(checkpoint_prefix.format(epoch=epoch))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 Loss 4.173699378967285\n","Epoch 1 Batch 100 Loss 2.3661739826202393\n","Epoch 1 Loss 2.1368\n","Time taken for the epoch: 904.8282017707825 sec\n","\n","Epoch 2 Batch 0 Loss 2.126349449157715\n","Epoch 2 Batch 100 Loss 1.904176950454712\n","Epoch 2 Loss 1.8429\n","Time taken for the epoch: 875.7926864624023 sec\n","\n","Epoch 3 Batch 0 Loss 1.76738440990448\n","Epoch 3 Batch 100 Loss 1.6135321855545044\n","Epoch 3 Loss 1.5937\n","Time taken for the epoch: 864.9985647201538 sec\n","\n","Epoch 4 Batch 0 Loss 1.6102852821350098\n","Epoch 4 Batch 100 Loss 1.5031448602676392\n","Epoch 4 Loss 1.5325\n","Time taken for the epoch: 857.3296134471893 sec\n","\n","Epoch 5 Batch 0 Loss 1.4522991180419922\n","Epoch 5 Batch 100 Loss 1.4587880373001099\n","Epoch 5 Loss 1.4327\n","Time taken for the epoch: 858.1769199371338 sec\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hMBmG2AlHdsx","colab_type":"text"},"source":["Test the model."]},{"cell_type":"code","metadata":{"id":"M7vPUs3JHe2m","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"outputId":"d6fc3ca6-c362-476c-d55a-f63af7a89c92","executionInfo":{"status":"ok","timestamp":1576724827659,"user_tz":-540,"elapsed":1293,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}}},"source":["model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n","model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","model.build(tf.TensorShape([1, None]))\n","model.summary()"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (1, None, 256)            16640     \n","_________________________________________________________________\n","gru_2 (GRU)                  (1, None, 1024)           3938304   \n","_________________________________________________________________\n","dense_2 (Dense)              (1, None, 65)             66625     \n","=================================================================\n","Total params: 4,021,569\n","Trainable params: 4,021,569\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gb3YKVh2IQih","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":663},"outputId":"874043a4-c245-458a-df7c-22b168bcacf2","executionInfo":{"status":"ok","timestamp":1576724963461,"user_tz":-540,"elapsed":8641,"user":{"displayName":"Sang-Yeon Hwang","photoUrl":"","userId":"15582350424285819444"}}},"source":["print(\n","    generate_text(model, start_string=u\"JULIET: \")\n",")"],"execution_count":28,"outputs":[{"output_type":"stream","text":["JULIET: a fear!\n","\n","BUCKINGHAM:\n","Poor Vantague, sir,--\n","\n","GRUMIO:\n","O, the shame of whats he will men of kiss\n","Internen hold men made a shalt\n","You was done for your heart, now not a kingdance esha'd:\n","In this envite is witholow.\n","\n","Medsenger: and he do'e; the omerient past cheiter: and cowfice\n","You might barect at him for all the crowning to so scrient?\n","O divine agas,\n","Harght, I contempt to Frolford,\n","Whom sho With witness to bed;\n","For she mother him.\n","\n","AUFIDIUS:\n","Thy hands! Fare ever mother,\n","For hills it stare in learn,\n","No ray can receive the enver rate was the thum I desire of our roy, promiceion\n","\n","joint me with this glars and seendly.\n","\n","FLORCE:\n","He ha! Do power me to great\n","Sigh so redied; that Gentleman so grace in my head;\n","But say'st thee was so ip ray; unto him.\n","\n","Perant:\n","Ploates of good comeo, to God, walking thee we execution.\n","Ines not children\n","Englock'd my visitiones of virtue, whomaticy hath his misin wrong\n","From mine officer? What,' then, let mill\n","Of ove go an exiumppozer.\n","An it, I'll have him so nigns\n","An I\n"],"name":"stdout"}]}]}