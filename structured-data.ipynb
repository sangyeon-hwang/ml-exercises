{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/alpha/tutorials/keras/feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Prepare a CSV data.\n",
    "dataURL = 'https://storage.googleapis.com/applied-dl/heart.csv'\n",
    "dataframe = pd.read_csv(dataURL)  # pandas.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The created `pandas.DataFrame` object has the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reversible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca        thal  target  \n",
       "0   0       fixed       0  \n",
       "1   3      normal       1  \n",
       "2   2  reversible       0  \n",
       "3   0      normal       0  \n",
       "4   0      normal       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'pandas.core.frame.DataFrame'>\n",
      "Shape: (303, 14)\n",
      "Column names and dtypes:\n",
      "age           int64\n",
      "sex           int64\n",
      "cp            int64\n",
      "trestbps      int64\n",
      "chol          int64\n",
      "fbs           int64\n",
      "restecg       int64\n",
      "thalach       int64\n",
      "exang         int64\n",
      "oldpeak     float64\n",
      "slope         int64\n",
      "ca            int64\n",
      "thal         object\n",
      "target        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Type:\", type(dataframe))\n",
    "print(\"Shape:\", dataframe.shape)\n",
    "print(\"Column names and dtypes:\")\n",
    "print(dataframe.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each *row* corresponds to a patient (or a data point), and each *column* corresponds to an attribute.\n",
    "\n",
    "Note that column values can be accessed by giving a column name as either an *attribute* or a *key*, i.e., `dataframe.age` or `dataframe['age']` for the age values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataframe into sub-dataframes for training, validating and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193, 14)\n",
      "(49, 14)\n",
      "(61, 14)\n"
     ]
    }
   ],
   "source": [
    "trainFrame, testFrame = train_test_split(dataframe, test_size=0.2)\n",
    "trainFrame, validateFrame = train_test_split(trainFrame, test_size=0.2)\n",
    "print(trainFrame.shape)\n",
    "print(validateFrame.shape)\n",
    "print(testFrame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we wrap each (sub-)dataframe into a `tensorflow.data.Dataset` object. The latter becomes a bridge that maps the dataframe to feature columns, which will be used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe2dataset(dataframe, shuffle=True, batchSize=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('target')  # 1,0-diagnosis of hear disease.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "        # dict(dataframe).keys() -> the data attributes.\n",
    "        # dict(dataframe).values() -> the data values.\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(dataframe))\n",
    "    dataset = dataset.batch(batchSize)  # Dataset -> BatchDataset\n",
    "    return dataset\n",
    "\n",
    "batchSize = 5  # A small batch size for demonstration.\n",
    "trainSet = dataframe2dataset(trainFrame, batchSize=batchSize)\n",
    "validateSet = dataframe2dataset(validateFrame, False, batchSize)\n",
    "testSet = dataframe2dataset(testFrame, False, batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`trainSet`, `validateSet` and `testSet` are `BatchDataset` objects. When iterated, they give one **batch** of data rows. Each batch is a *tuple* of a **feature batch** and a **label batch**. The feature batch is a dict mapping the column names to values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type and length: <class 'tuple'> , 2\n",
      "batch[0] keys: ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
      "batch[0] value example: tf.Tensor([62 40 49 58 55], shape=(5,), dtype=int32)\n",
      "batch[1]: tf.Tensor([0 0 0 0 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "exampleBatch = next(iter(trainSet))\n",
    "print(\"Type and length:\", type(exampleBatch), \",\", len(exampleBatch))\n",
    "print(\"batch[0] keys:\", list(exampleBatch[0].keys()))\n",
    "print(\"batch[0] value example:\", exampleBatch[0]['age'])\n",
    "print(\"batch[1]:\", exampleBatch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original data has different types of features, e.g., numerical, categorical or binary. `tensorflow.feature_column` provides various types of feature columns.\n",
    "\n",
    "We will use the following helper function to see some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect(featureColumn):\n",
    "    \"\"\"A utility function to see how a feature batch is transformed\n",
    "       to a feature column.\"\"\"\n",
    "    # First construct a feature layer.\n",
    "    featureLayer = tf.keras.layers.DenseFeatures(featureColumn)\n",
    "    # Provide an example batch to the layer,\n",
    "    transformedBatch = featureLayer(exampleBatch[0])\n",
    "    # and see how the raw input is transformed.\n",
    "    print(transformedBatch.numpy(), \", shape:\", transformedBatch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62.]\n",
      " [40.]\n",
      " [49.]\n",
      " [58.]\n",
      " [55.]] , shape: (5, 1)\n",
      "tf.Tensor([62 40 49 58 55], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "age = tf.feature_column.numeric_column('age')\n",
    "inspect(age)\n",
    "print(exampleBatch[0]['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Bucketized columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]] , shape: (5, 11)\n"
     ]
    }
   ],
   "source": [
    "ageBuckets = tf.feature_column.bucketized_column(\n",
    "    age,\n",
    "    boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65]\n",
    ")\n",
    "inspect(ageBuckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]] , shape: (5, 3)\n",
      "tf.Tensor([b'normal' b'reversible' b'normal' b'normal' b'reversible'], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "thal = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'thal', ['fixed', 'normal', 'reversible'])\n",
    "thalOneHot = tf.feature_column.indicator_column(thal)\n",
    "inspect(thalOneHot)\n",
    "print(exampleBatch[0]['thal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Embedding columns.\n",
    "<br>Dense embedding of a categorical one-hot with a large number of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06894064  0.3722002   0.29687527 -0.03388098  0.04981663 -0.5150623\n",
      "   0.17188948 -0.3192951 ]\n",
      " [ 0.10701027 -0.540475   -0.38190898 -0.21986264  0.6362094  -0.5586064\n",
      "  -0.58962834 -0.59624755]\n",
      " [ 0.06894064  0.3722002   0.29687527 -0.03388098  0.04981663 -0.5150623\n",
      "   0.17188948 -0.3192951 ]\n",
      " [ 0.06894064  0.3722002   0.29687527 -0.03388098  0.04981663 -0.5150623\n",
      "   0.17188948 -0.3192951 ]\n",
      " [ 0.10701027 -0.540475   -0.38190898 -0.21986264  0.6362094  -0.5586064\n",
      "  -0.58962834 -0.59624755]] , shape: (5, 8)\n"
     ]
    }
   ],
   "source": [
    "thalEmbedding = tf.feature_column.embedding_column(thal, dimension=8)\n",
    "inspect(thalEmbedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Hashed feature columns.\n",
    "<br>Use `hash_bucket_size` number of hash buckets to encode category strings. `hash_bucket_size` can be much smaller than the vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] , shape: (5, 1000)\n"
     ]
    }
   ],
   "source": [
    "thalHashed = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    'thal', hash_bucket_size=1000)\n",
    "inspect(tf.feature_column.indicator_column(thalHashed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Crossed feature columns.\n",
    "<br>Hash encoding of **feature crosses**. The example below crosses the two features, age and thal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] , shape: (5, 1000)\n"
     ]
    }
   ],
   "source": [
    "ageThalCross = tf.feature_column.crossed_column(\n",
    "    [ageBuckets, thal], hash_bucket_size=1000)\n",
    "ageThalOneHot = tf.feature_column.indicator_column(ageThalCross)\n",
    "inspect(ageThalOneHot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now collect the feature columns that we will use to transform our raw input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureColumns = []\n",
    "# Numeric columns\n",
    "for header in ['age', 'trestbps', 'chol', 'thalach',\n",
    "               'oldpeak', 'slope', 'ca']:\n",
    "    featureColumns.append(tf.feature_column.numeric_column(header))\n",
    "# Bucketized columns\n",
    "featureColumns.append(ageBuckets)\n",
    "# Indicator columns\n",
    "featureColumns.append(thalOneHot)\n",
    "# Embedding columns\n",
    "featureColumns.append(thalEmbedding)\n",
    "# Crossed columns\n",
    "featureColumns.append(ageThalOneHot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the feature columns, we define a feature layer, as done in `inspect`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureLayer = tf.keras.layers.DenseFeatures(featureColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we resplit the dataset using a larger batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 32\n",
    "trainSet = dataframe2dataset(trainFrame, batchSize=batchSize)\n",
    "validateSet = dataframe2dataset(validateFrame, False, batchSize)\n",
    "testSet = dataframe2dataset(testFrame, False, batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we define, compile, train and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 2.0321 - accuracy: 0.6461 - val_loss: 1.2919 - val_accuracy: 0.6735\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 50ms/step - loss: 0.8662 - accuracy: 0.6443 - val_loss: 0.7991 - val_accuracy: 0.6531\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.5290 - accuracy: 0.8018 - val_loss: 0.7434 - val_accuracy: 0.6122\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 50ms/step - loss: 0.5945 - accuracy: 0.7369 - val_loss: 0.7268 - val_accuracy: 0.6939\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.4706 - accuracy: 0.7816 - val_loss: 0.6296 - val_accuracy: 0.7347\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5744 - accuracy: 0.6557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.574438214302063, 0.6557377]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    featureLayer,\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(trainSet,\n",
    "          validation_data=validateSet,\n",
    "          epochs=5)\n",
    "model.evaluate(testSet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
